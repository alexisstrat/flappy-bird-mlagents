Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
23250000,0.054430287,9.67462,333.3333333333333,32.433335979779564,32.433335979779564,0.11531234,0.02646855,0.00016061262,0.1535375,0.002681522,1.0
23300000,0.055719025,9.669356,1949.0625,194.00626707449555,194.00626707449555,0.26517096,0.024112295,0.0001603568,0.15345225,0.002677267,1.0
23350000,0.05242261,9.698045,2891.1111111111113,288.2111367351479,288.2111367351479,0.15877223,0.023657475,0.00016004794,0.15334931,0.00267213,1.0
23400000,0.05282141,9.745133,4264.1,425.5100377559662,425.5100377559662,0.1649886,0.022133658,0.00015973982,0.15324658,0.0026670045,1.0
23450000,0.052566335,9.771444,3570.2727272727275,356.12730411236936,356.12730411236936,0.1890467,0.024759522,0.00015943078,0.15314358,0.0026618645,1.0
23500000,0.054213937,9.78824,5390.5,538.1500478461385,538.1500478461385,0.11992371,0.023551991,0.00015915159,0.15305051,0.0026572202,1.0
23550000,0.05595437,9.843977,3831.1111111111113,382.2111449374093,382.2111449374093,0.16918166,0.02412931,0.00015887283,0.15295759,0.002652584,1.0
23600000,0.05673902,9.877865,4393.166666666667,438.4167055537303,438.4167055537303,0.15743233,0.02360135,0.00015856457,0.15285483,0.002647456,1.0
23650000,0.0544823,9.888316,3925.8,391.6800346672535,391.6800346672535,0.22778323,0.022095624,0.00015825519,0.15275171,0.0026423102,1.0
23700000,0.055751372,9.864226,2018.375,200.93751752376556,200.93751752376556,0.17201135,0.022803955,0.00015794676,0.1526489,0.00263718,1.0
23750000,0.057187416,9.840139,4952.2,494.3200439423323,494.3200439423323,0.16350153,0.02354993,0.0001576382,0.15254605,0.0026320475,1.0
